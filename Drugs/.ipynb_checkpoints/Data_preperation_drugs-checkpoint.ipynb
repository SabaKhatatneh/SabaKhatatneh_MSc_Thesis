{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's check files are in the correct directory\n",
    "import os\n",
    "files_needed_GSE92742=['GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx',\n",
    "               'GSE92742_Broad_LINCS_gene_info.txt','GSE92742_Broad_LINCS_sig_info.txt']\n",
    "files_needed_GSE70138=['GSE70138_Broad_LINCS_Level5_COMPZ_n118050x12328.gctx',\n",
    "                      'GSE70138_Broad_LINCS_sig_info.txt', 'GSE92742_Broad_LINCS_gene_info.txt']\n",
    "files_needed_rep=['repurposing_drugs_20180907.txt','repurposing_samples_20180907.txt']\n",
    "files_GSE92742=os.listdir('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/GSE92742/')\n",
    "files_GSE70138=os.listdir('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/GSE70138/')\n",
    "files_rep=os.listdir('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/')\n",
    "for f in files_needed_GSE92742:\n",
    "    assert (f in files_GSE92742)\n",
    "for f in files_needed_GSE70138:\n",
    "    assert (f in files_GSE70138)\n",
    "for f in files_needed_rep:\n",
    "    assert (f in files_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general data manipulations\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "#cmapPy\n",
    "from cmapPy.pandasGEXpress.parse import parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this analysis we won't work with the individual signatures, but will caculate a consensus (average) signature for a given gene knockout. However further filtering / using of individual signatures are highly encouraged. To calculate consensus signature, we will use the MODZ method described in the original LINCS manuscript."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr as scor\n",
    "def calc_MODZ(data):\n",
    "    \"\"\"calculates MODZ based on the original CMAP/L1000 study\n",
    "    use only lm genes for MODZ calculation! Uses LM_GENES global\n",
    "    variable.\"\"\"\n",
    "    if len(data)==1:\n",
    "        return data.iloc[0]\n",
    "    if len(data)==2:\n",
    "        return np.mean(data,0)\n",
    "    else:\n",
    "        CM=scor(data.T)[0]\n",
    "        fil=CM<0\n",
    "        CM[fil]=0.01\n",
    "        weights=np.sum(CM,1)-1\n",
    "        weights=weights/np.sum(weights)\n",
    "        weights=weights.reshape((-1,1))\n",
    "        return pd.Series(np.dot(data.T,weights).reshape((-1,1)[0]),index=data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rid\n",
       "780    -0.370345\n",
       "7849   -0.021135\n",
       "6193    0.446688\n",
       "23     -0.631813\n",
       "9552   -0.688607\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#so this is the consensus signature of the A2M gene knockdown\n",
    "calc_MODZ(expression).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pr_gene_id</th>\n",
       "      <th>780</th>\n",
       "      <th>7849</th>\n",
       "      <th>6193</th>\n",
       "      <th>23</th>\n",
       "      <th>9552</th>\n",
       "      <th>387</th>\n",
       "      <th>10921</th>\n",
       "      <th>10285</th>\n",
       "      <th>533</th>\n",
       "      <th>6194</th>\n",
       "      <th>...</th>\n",
       "      <th>54681</th>\n",
       "      <th>11000</th>\n",
       "      <th>6915</th>\n",
       "      <th>6253</th>\n",
       "      <th>7264</th>\n",
       "      <th>5467</th>\n",
       "      <th>2767</th>\n",
       "      <th>23038</th>\n",
       "      <th>57048</th>\n",
       "      <th>79716</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>A2M</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AARS</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AATF</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABAT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABCA1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 978 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "pr_gene_id  780 7849 6193   23 9552  387 10921 10285  533 6194  ... 54681  \\\n",
       "A2M         NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN  ...   NaN   \n",
       "AARS        NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN  ...   NaN   \n",
       "AATF        NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN  ...   NaN   \n",
       "ABAT        NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN  ...   NaN   \n",
       "ABCA1       NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN  NaN  NaN  ...   NaN   \n",
       "\n",
       "pr_gene_id 11000 6915 6253 7264 5467 2767 23038 57048 79716  \n",
       "A2M          NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "AARS         NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "AATF         NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "ABAT         NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "ABCA1        NaN  NaN  NaN  NaN  NaN  NaN   NaN   NaN   NaN  \n",
       "\n",
       "[5 rows x 978 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we will store perturabtion expression profiles in a DataFrame\n",
    "#rows are the perturbed genes, columns are the measured landmark genes from LINCS\n",
    "genes_perturbed=sig_info_shRNA['pert_iname'].unique()\n",
    "consensus_signatures_shRNA=pd.DataFrame(index=genes_perturbed,columns=gene_ids.index)\n",
    "consensus_signatures_shRNA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done for 0 genes\n",
      "Done for 100 genes\n",
      "Done for 200 genes\n",
      "Done for 300 genes\n",
      "Done for 400 genes\n",
      "Done for 500 genes\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(genes_perturbed)):\n",
    "    if (i%100)==0:\n",
    "        print('Done for %i genes' %i)\n",
    "    gene=genes_perturbed[i]\n",
    "    fil=sig_info_shRNA['pert_iname']==gene\n",
    "    samples=sig_info_shRNA.index[fil]\n",
    "    expression=parse('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/GSE92742/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx',\n",
    "                 cid=samples,rid=gene_ids.index).data_df.T[gene_ids.index]\n",
    "    consensus_signatures_shRNA.loc[gene]=calc_MODZ(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename LINCS gene ids for gene symbolc\n",
    "consensus_signatures_shRNA.columns=gene_ids[consensus_signatures_shRNA.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_signatures_shRNA.to_csv('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/results/consensus_signature_shRNA.csv',sep=',')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we can use the consensus_signature_shRNA.csv file for the models. The same file is also available in Synapse. While this data only contains consensus signatures, further experiments with individual signatures can further increase model perferomance, and are highly encouraged.\n",
    "\n",
    "#### Now we will do the same consensus signature calculations for drugs. We will use both GSE92742 and GSE70138."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_info_gse92742=pd.read_csv('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/GSE92742/GSE92742_Broad_LINCS_sig_info.txt',\n",
    "                              sep='\\t',header=0,index_col=0,low_memory=False)\n",
    "sig_info_gse70138=pd.read_csv('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/GSE70138/GSE70138_Broad_LINCS_sig_info.txt',\n",
    "                              sep='\\t',header=0,index_col=0,low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only compoud treatments\n",
    "fil=sig_info_gse92742['pert_type']=='trt_cp'\n",
    "sig_info_gse92742=sig_info_gse92742[fil]\n",
    "fil=sig_info_gse70138['pert_type']=='trt_cp'\n",
    "sig_info_gse70138=sig_info_gse70138[fil]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get all compounds\n",
    "cpds=list(set(sig_info_gse70138['pert_id']) | set(sig_info_gse92742['pert_id']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To get the targets of these drugs - when target is known - we need compound metadata from Drug Repurposing Hub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read drug repurposing data\n",
    "repurposing=pd.read_csv('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/repurposing_drugs_20180907.txt',sep='\\t',encoding='latin',\n",
    "                    header=0,index_col=None,skiprows=9)\n",
    "repurposing_samples=pd.read_csv('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/repurposing_samples_20180907.txt',sep='\\t',encoding='latin',\n",
    "                    header=0,index_col=None,skiprows=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correct broad_id\n",
    "repurposing_samples['broad_id']=repurposing_samples['broad_id'].apply(lambda x: '-'.join(x.split('-')[:2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select usefull columns\n",
    "repurposing_samples=repurposing_samples[['broad_id','pert_iname']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repurposing=repurposing[['pert_iname','moa','target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge repurposing data\n",
    "drug_metadata=pd.merge(repurposing,repurposing_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove duplicated\n",
    "drug_metadata=drug_metadata.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep only rows with known target / MoA\n",
    "fil=~(drug_metadata['moa'].isnull() & drug_metadata['target'].isnull())\n",
    "drug_metadata=drug_metadata[fil]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#matching compounds between repurposing and LINCS dataset\n",
    "cpds=list(set(cpds) & set(drug_metadata['broad_id']))\n",
    "fil=np.in1d(drug_metadata['broad_id'],cpds)\n",
    "drug_metadata=drug_metadata[fil]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_metadata.index=range(len(drug_metadata))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select all targets / MoAs\n",
    "all_moas=[]\n",
    "all_targets=[]\n",
    "for i in drug_metadata.index:\n",
    "    if not pd.isnull(drug_metadata.loc[i,'target']):\n",
    "        all_targets+=drug_metadata.loc[i,'target'].split('|')\n",
    "    if  not pd.isnull(drug_metadata.loc[i,'moa']):\n",
    "        all_moas+=drug_metadata.loc[i,'moa'].split('|')\n",
    "all_moas=list(set(all_moas))\n",
    "all_targets=list(set(all_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_matrix=pd.DataFrame(0,index=list(set(drug_metadata['broad_id'])),columns=all_moas+all_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for compunds where inhibitor,blocker,antagonist etc. are in the MoA columns\n",
    "#we assume they are inhibitory compounds, so we will mark them with -1 in the meta_matrix\n",
    "# for other compounds, we assume they are activators, we will mark them with +1\n",
    "#this is probably not a perfect way to access inhibitory/acovatory state, but good for a first try\n",
    "inhibitory_words=set(['inhibitor','blocker','antagonist','inihibitor']) #inihibitor is just a typo\n",
    "for i in drug_metadata.index:\n",
    "    if list(drug_metadata.index).index(i) % 100==0:\n",
    "        print('Done for %i drugs' %list(drug_metadata.index).index(i))\n",
    "    brd=drug_metadata.loc[i,'broad_id']\n",
    "    if not pd.isnull(drug_metadata.loc[i,'moa']):\n",
    "        moas=drug_metadata.loc[i,'moa'].split('|')\n",
    "    else:\n",
    "        moas=[]\n",
    "    if not pd.isnull(drug_metadata.loc[i,'target']):\n",
    "        s=1\n",
    "        targets=drug_metadata.loc[i,'target'].split('|')\n",
    "        if len(set((' '.join(moas)).split())&inhibitory_words)>0:\n",
    "            s=-1\n",
    "    else:\n",
    "        s=1\n",
    "        targets=[]\n",
    "    meta_matrix.loc[brd,moas]=1\n",
    "    meta_matrix.loc[brd,targets]=s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_matrix.to_csv('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/results/drugs_meta.csv',sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Now we will get the consensus signature for each drug, and store them in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_signatures_drugs=pd.DataFrame(index=meta_matrix.index,columns=gene_ids.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(consensus_signatures_drugs.index)):\n",
    "    drug=consensus_signatures_drugs.index[i]\n",
    "    if i%100==0:\n",
    "        print('Done for %i drugs' % i)\n",
    "    fil=sig_info_gse70138['pert_id']==drug\n",
    "    if fil.sum()>0:\n",
    "        samples=sig_info_gse70138.index[fil]\n",
    "        expression_gse70138=parse('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/GSE70138/GSE70138_Broad_LINCS_Level5_COMPZ_n118050x12328.gctx',\n",
    "                                  cid=samples,rid=gene_ids.index).data_df.T[gene_ids.index]\n",
    "    else:\n",
    "        expression_gse70138=pd.DataFrame(columns=gene_ids.index)\n",
    "    fil=sig_info_gse92742['pert_id']==drug\n",
    "    if fil.sum()>0:\n",
    "        samples=sig_info_gse92742.index[fil]\n",
    "        expression_gse92742=parse('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/GSE92742/GSE92742_Broad_LINCS_Level5_COMPZ.MODZ_n473647x12328.gctx',\n",
    "                                  cid=samples,rid=gene_ids.index).data_df.T[gene_ids.index]\n",
    "    else:\n",
    "        expression_gse92742=pd.DataFrame(columns=gene_ids.index)\n",
    "    expression=pd.concat([expression_gse70138,expression_gse92742])\n",
    "    consensus_signatures_drugs.loc[drug]=calc_MODZ(expression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename L1000 gene ids for gene names\n",
    "consensus_signatures_drugs.columns=gene_ids[consensus_signatures_drugs.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consensus_signatures_drugs.to_csv('C:/Users/Saba/Desktop/Tutored research project/DrugRepurposing/data/Drugs/results/consensus_signature_drugs.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myEnv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
